SUBJECT: Re : mtg ? sorry meant to send this . It 's my abstract for &NAME . &NAME &NAME - &NAME University &EMAIL &ORG &NAME &NAME Building &NUM &NAME &NAME Avenue &NAME &NAME &NAME &NAME A Computational Model for Lexical Acquisition of a Categorial Grammar A model of lexical acquisition has been developed in order to learn both the semantic and syntactic category of lexemes associated with a generalised categorial grammar . Computational simulation shows that acquisition is possible when some prior language knowledge is assumed . The effects on acquisition have been explored when aspects of this prior knowledge are varied . At this conference &CHAR would present the acquisition model , focusing particularly on the novel syntax learner , as well as the results of acquisition experiments that have been run from different starting points in terms of the prior knowledge assumed . In child language acquisition theory it has been suggested that children have an innate ability to recognise the category of particular types of words and this ability in turn helps them to determine the category of other words . Whether this innate ability to categorise applies to ' names and object words ' or ' actions words ' has been much discussed . The difference in acquisition rate in each case is investigated . The method assumes a pipelined approach to acquisition . Each utterance in turn is first processed for the acquisition of semantic information and subsequently for the acquisition of syntactic information . It is assumed that this is compatible with children 's behaviour . It is likely that children acquire all the information they can from an utterance when they hear it and then discard it . It would be impractical for the child to store many utterances to process later . The syntactic learner relies on output from the semantic learner . This also echos children 's behaviour since they pass through a single word acquisition phase before they begin to acquire syntax . The semantic learner produces a mapping between words and their semantic representation using , amongst others , the theories of cross-situational learning and covering constraints and is based on &NAME 's work on &NAME &NAME Techniques . A fundamental assumption is employed to link the &NUM learners ; the number of words that the semantic category of a word is dependent upon is the same as the number of words that the syntactic category is dependent upon . The syntactic learner attempts to create valid parse trees for the categorial grammar thus resolving unknowns in the syntactic category types . This is achieved by first assigning skeleton categories to words in the current utterance - using the fundamental assumption in conjunction with information already extracted by the semantic learner . All possible binary tree structures for the utterance are then considered . &NAME trees are discarded whilst any valid trees add weighting to the syntactic categories of words at their leaf nodes . For a very simple example consider the sentence ' The grinch cries ' . Using the scenario where children have an innate ability to recognise names and objects , we already know that : ' grinch ' is of semantic category &NAME and syntactic category &CHAR , In order to find a skeleton category for the remaining words we look at their semantic category and then apply the fundamental assumption : ' the ' has semantic category THE ( &CHAR ) and syntactic category x|y ' cries ' has semantic category &NAME ( &CHAR ) and syntactic category u|v where | is used to represent either forward or backward application and &CHAR , &CHAR , &CHAR , &CHAR are syntactic categories ( which may be either atomic or complex ) . A possible parse tree for this sentence is : &CHAR ? u|v / ' cries ' x|y &CHAR ' The ' ' &NAME ' The syntax learner could then discover the following unknowns : &CHAR &CHAR sx / ' cries ' &CHAR / &CHAR &CHAR ' The ' ' &NAME ' The input to the system is a collection of utterances paired with semantic representations . These semantic representations are the hypothesised meanings a child may assume for an utterance . The correct interpretation may or may not be included amongst the semantic representations . The affect of this type of noise on the system may also be investigated . Children learn their native tongue because it is the language of their environment . In the early stages of acquisition the only language that children are exposed to is that of their caketakers . This implies that the caretakers ' utterances are the only input needed to begin acquisition . To mirror this situation , from which children actually learn , I use real data ; the interaction between a child and her parents . Since the child involved did successfully learn English , it is reasonable to assume that the utterances the child heard the parents say are sufficient for learning ( provided a capable model and correct starting assumptions can be found ) . The &NAME 's Corpus of the &NAME database has been used for this work . The corpus contains a selection of interactions between a child and her parents from the age of &NUM year &NUM month to &NUM years and &NUM month . The corpus has been preprocessed by &NAME . All phonological annotations and grammatical structures not covered by her grammar , including interjections and elliptical material , have been removed . The child 's sentences were also excluded from those remaining so that the parents ' sentences only are given as input to the system . The learner has been run on the first &NUM utterances of the corpus . The semantics learner will currently achieve recall of &NUM with precision &NUM . The syntactic learner is dependant upon the recall of the semantic learner in that it can only proceed when a skeleton syntactic category is available for every word in the utterance ; when this is the case the success rate is high with precision in the high &NAME . A previous investigation into lexical acquisition in the framework of a categorial grammar was discussed by &NAME . His approach differs from this in several respects . &NAME 's syntactic learner was entirely algebraic in nature ; the syntactic categories were derived by solving a set of simultaneous equations . In order to constrain his search space &NAME had to specify the syntactic categories allowed . This meant defining a category set before learning began . This is equivalent to assuming a child has innate knowledge of which syntactic categories are allowed in it 's language . The learner presented here is not restricted in this way . &NAME 's learner was used in conjunction with a parameter setting system ( &NAME ) in order to &NAME hypothesised category sets . For this purpose the learner was successful but &NAME still made several assumptions that would correspond to innate language ability in a child . In order to investigate these assumptions a new learning model is needed . The learner presented can acquire language from reasonably little prior knowledge and as a result the effects on learning rate as introduced by these and other assumptions can be investigated . References : &NAME &NAME - Learning Natural Language within the Framework of Categorial Grammar - 3rd &NAME &NAME Research Colloquium , &NUM . &NAME &NAME - A Computational Study of &NAME &NAME Techniques for Learning Word-to-Meaning Mappings - &NAME &NAME num.1-2 pp. &NUM , &NAME / &NAME &NUM &NAME &NAME - The Acquisition of a Unification-Based Generalised Categorial Grammar - &NAME &NAME , &NAME University , &NUM 